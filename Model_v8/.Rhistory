log(2)
#constants file
rm(list=ls())
if(.Platform$OS.type=="windows"  & Sys.info()["user"]=="Ashish") {
csv_dir <- "C:\\Users\\Ashish\\Desktop\\Velib Data\\CSVData"
work_dir <- "C:/Users/Ashish/Dropbox/Ashish_Karan/Sustainable Transportation System/Data/Code/R/New Choice Model_v5_GMM_discoef"
dropbox_dir <- "C:/Users/Ashish/Dropbox/Ashish_Karan"
} else {
if(.Platform$OS.type=="windows") {
csv_dir <- "C:\\Users\\kabra\\Desktop\\Projects\\Velib Data\\Data\\CSVData"
work_dir <- "C:/Users/kabra/Dropbox/Ashish_Karan/Sustainable Transportation System/Data/Code/R/New Choice Model_v5_GMM_discoef"
dropbox_dir <- "C:/Users/kabra/Dropbox/Ashish_Karan"
}
else {
if((Sys.info()["user"])=="ashish") {
#incidates my linux machine
work_dir <- "/home/ashish/Dropbox/Ashish_Karan/Sustainable Transportation System/Data/Code/R/New Choice Model_v5_GMM_discoef"
csv_dir <- "/home/ashish/Desktop/Velib_Data/CSVData"
dropbox_dir <- "/home/ashish/Dropbox/Ashish_Karan"
#options(fftempdir="/home/ashish/fftempdir")
}
if((Sys.info()["user"])=="ak") {
#incidates my linux machine
work_dir <- "/home/ak/Dropbox/Ashish_Karan/Sustainable Transportation System/Data/Code/R/New Choice Model_v5_GMM_discoef"
csv_dir <- "/home/ak/Desktop/Velib_Data/CSVData"
dropbox_dir <- "/home/ak/Dropbox/Ashish_Karan"
}
if((Sys.info()["user"])=="rstudio") {
csv_dir <- "/home/rstudio/workspace/CSVData"
work_dir <- "/home/rstudio/Data/New Choice Model_v5_GMM_discoef"
dropbox_dir <- "/home/ubuntu/Dropbox/Ashish_Karan"
}
}
}
st_id_file <- "Paris/st_id_data_01_07_13.txt"
max_walking_dis <- 0.3
library('nloptr')
library('ffbase')
library('biglm')
library('sfsmisc')
library("Rcpp")
library("RcppArmadillo")
library("ipoptr")
library("plm")
setwd(work_dir)
source("setup.R")
options(digits=10)
#for ffdf chunk size
options(ffbatchbytes=167772160)
#obj.size <- napply(names, function(x) round(object.size(x)/1024^2,2))
.ls.objects <- function (pos = 1, pattern, order.by,
decreasing=FALSE, head=FALSE, n=5) {
napply <- function(names, fn) sapply(names, function(x)
fn(get(x, pos = pos)))
names <- ls(pos = pos, pattern = pattern)
obj.class <- napply(names, function(x) as.character(class(x))[1])
obj.mode <- napply(names, mode)
obj.type <- ifelse(is.na(obj.class), obj.mode, obj.class)
#obj.size <- napply(names, object.size)
obj.size <- napply(names, function(x) round(object.size(x)/1024^2,2))
obj.dim <- t(napply(names, function(x)
as.numeric(dim(x))[1:2]))
vec <- is.na(obj.dim)[, 1] & (obj.type != "function")
obj.dim[vec, 1] <- napply(names, length)[vec]
out <- data.frame(obj.type, obj.size, obj.dim)
names(out) <- c("Type", "Size", "Rows", "Columns")
if (!missing(order.by))
out <- out[order(out[[order.by]], decreasing=decreasing), ]
if (head)
out <- head(out, n)
out
}
# shorthand
lsos <- function(..., n=10) {
.ls.objects(..., order.by="Size", decreasing=TRUE, head=TRUE, n=n)
}
source("constants.R")
#v3.0 two stockstate observations per stations, if results are consistent, can experiment with other fixed effects etc.
point_range <- 1
source("eval_func_4_GMM_new_temp_2.86_2.R")
source("data_prep_functions_ffdf_limstostate.R")
source("data_prep_inte_points_limstostate.R")
source("eval_func_2_cpp_cntrt_map_2.86_2.R")
source("eval_func_3_cpp_new_2.86_2.R")
#max_walking_dis = 0.1
tract_list <- list(1:10)
for(tract in tract_list) {
st_list = select_stations_in_tract(c(tract))
#temporary - load st_6_7_8 file, should be able to generate this realtime,
save_dir <- paste0(csv_dir,"/ffdb/Paris/st_5_8")
load(save_dir)
st_list <- intersect(st_5_8,st_list)
filelist_all <- c("Paris/ind_paris_5.csv","Paris/ind_paris_6.csv",
"Paris/ind_paris_7.csv","Paris/ind_paris_8.csv")
filelist_all_mons <- c(5:8)
#   filelist_all <- c("Paris/ind_paris_7.csv")
#   filelist_all_mons <- c(7)
#filelist_servlvl <- c("Paris/ind_paris_4.csv","Paris/ind_paris_5.csv")
wdcMerged <- c()
for( i in 1:length(filelist_all_mons)) {
filelist <- filelist_all[i]
mon <- filelist_all_mons[i]
save_file <- paste0(csv_dir,"/ffdb/wdcMerged_bootstrap_limstostate_5_8_",
point_range,"/tract_",paste0(tract,collapse="_"),"_mon_",mon)
print(save_file)
#load files
wdcMerged_bootstrap <- reg_run_bootstrap_simple(NULL,save_file)
dim(wdcMerged_bootstrap)
wdcMerged <- rbind(wdcMerged,wdcMerged_bootstrap)
rm(wdcMerged_bootstrap)
}
wdcMerged_save <- wdcMerged
#wdcMerged_save <- subset(wdcMerged_save, tw>=6 & tw <10)
wdcMerged_save <- droplevels(wdcMerged_save)
no_bootstrap_runs <- 1
#v0_vec <- generate_v0() #necessary to generate outside as seed is otherwise set inside, bad
v0_vec <- c(0)
set.seed(2)
reg_runs_save_file <- "reg_runs_discoef_2.86_2_4states_pr1_bootstrap.txt"
i=1
for(i in 1:no_bootstrap_runs) {
print(i)
wdcMerged <- wdcMerged_save
if(i==1) {
a = as.ff(1:nrow(wdcMerged))
} else {
a = as.ff(sample.int(nrow(wdcMerged), size = nrow(wdcMerged), replace = TRUE))
wdcMerged = wdcMerged[a,]
wdcMerged <- droplevels(wdcMerged)
}
#construct alternative measures to stocked out, <=5 bikes, <=5% bikes
wdcMerged$station_size <- wdcMerged$bikes + wdcMerged$spaces_available
wdcMerged$less_5_bikes <- (wdcMerged$bikes<=5)
wdcMerged$less_3_bikes <- (wdcMerged$bikes<=3)
wdcMerged$less_7_bikes <- (wdcMerged$bikes<=7)
wdcMerged$less_5perc_bikes <- wdcMerged$bikes/wdcMerged$station_size
wdcMerged$less_5perc_bikes <- (wdcMerged$less_5perc_bikes<=0.05)
wdcMerged$week <- floor(wdcMerged$day/28)
#wdcMerged$tw <- floor(wdcMerged$tw/4)
wdcMerged_save_i <- wdcMerged
#compute demand at the level of st,week,tw,sto_state
#wdcMerged <- subset(wdcMerged, stocked_out==FALSE)
#since aggdata aggregates over stid_twg_locstate_fac,
wdcMerged$stid_twg_locstate_fac <-  as.ff(as.factor(paste(wdcMerged$station_id_index[],
wdcMerged$week[],wdcMerged$tw[],wdcMerged$sto_state_local[])))
wdcMerged$stid_twg_locstate_fac <- droplevels(wdcMerged$stid_twg_locstate_fac)
wdcMerged <- aggdata(wdcMerged)
wdcMerged$out_dem_mean <- wdcMerged$out_dem_sum/wdcMerged$obs_weight
wdcCenTrParsed <- readtractboundaryfile()
station_data <- unique(wdcMerged[,c("station_id","lat","lon","station_id_index")])
station_data$tract  <- assign_points_tract(station_data$lat,station_data$lon,wdcCenTrParsed)
station_data <- station_data[,c("station_id_index","tract")]
wdcMerged <- merge(wdcMerged,station_data,by="station_id_index")
wdcMerged$tract_tw <- as.factor(paste0(wdcMerged$tract[],"_",wdcMerged$tw))
wdcMerged$station_id_index_fac <- as.factor(wdcMerged$station_id_index)
wdcMerged$week_fac <- as.factor(wdcMerged$week)
wdcMerged$tract_tw_fac <- as.factor(wdcMerged$tract_tw)
#doign the demand prefitting by tract seperately since the interaction terms in twxtract
#introduce tract fixed effects which are collinear with station fixed effects and there
#is no easy way to remove it.
wdcMerged$stid_locstate_fac <- as.factor(paste0(wdcMerged$station_id_index," ",wdcMerged$sto_state_local))
stocked_list <- which(wdcMerged$stocked_out==FALSE)
fit2 <- biglm(out_dem_mean ~ week_fac + tract_tw_fac + 0, data=wdcMerged[stocked_list,],
weights=~wdcMerged$obs_weight[stocked_list])
fit2_resid <- wdcMerged$out_dem_mean[stocked_list]-predict(fit2,newdata=wdcMerged[stocked_list,])
wdcMerged$out_dem_mean[stocked_list] <- fit2_resid
wdcMerged$out_dem_sum_2 <- 0
wdcMerged$out_dem_sum_2[stocked_list] <- wdcMerged$out_dem_mean[stocked_list]*
wdcMerged$obs_weight[stocked_list]
#we need an intercept to out_dem_mean which will make the sum of of out_dem_sum column
#equal to out_dem_sum_2 column
intecept = (sum(wdcMerged$out_dem_sum[stocked_list]) -
sum(wdcMerged$out_dem_sum_2[stocked_list]))/sum(wdcMerged$obs_weight[stocked_list])
wdcMerged$out_dem_sum_2[stocked_list] <- (wdcMerged$out_dem_mean[stocked_list]+intecept)*
wdcMerged$obs_weight[stocked_list]
wdcMerged$out_dem_sum[stocked_list] <- wdcMerged$out_dem_sum_2[stocked_list]
wdcMerged$out_dem_sum_2 <- NULL
wdcMerged$out_dem_sum[which(wdcMerged$out_dem_sum < 0)] <- 0
#wdcMerged <- subset(wdcMerged, tw>=1 & tw<5)
wdcMerged <- droplevels(wdcMerged)
wdcMerged_dem <- wdcMerged
#construct the service level at station level
wdcMerged <- wdcMerged_save_i
#wdcMerged <- subset(wdcMerged, tw>=1 & tw<5)
wdcMerged <- droplevels(wdcMerged)
#generate group by factor
wdcMerged$groupbyfactor <- as.ff(as.factor(paste(wdcMerged$station_id_index[],
wdcMerged$week[],wdcMerged$tw[])))
agg_serv_lvl = binned_sum(wdcMerged$stocked_out, bin=wdcMerged$groupbyfactor)
agg_serv_lvl = as.data.frame(agg_serv_lvl)
agg_serv_lvl$groupbyfactor = row.names(agg_serv_lvl)
agg_serv_lvl$serv_lvl <- 1-(agg_serv_lvl$sum/agg_serv_lvl$count)
length(which(agg_serv_lvl$serv_lvl==0))
agg <- agg_serv_lvl
agg_serv_lvl <- NULL
agg_serv_lvl_less_5_bikes = binned_sum(wdcMerged$less_5_bikes, bin=wdcMerged$groupbyfactor)
agg_serv_lvl_less_5_bikes = as.data.frame(agg_serv_lvl_less_5_bikes)
agg_serv_lvl_less_5_bikes$groupbyfactor = row.names(agg_serv_lvl_less_5_bikes)
agg_serv_lvl_less_5_bikes$serv_lvl <- 1-(agg_serv_lvl_less_5_bikes$sum/agg_serv_lvl_less_5_bikes$count)
agg$serv_lvl_less_5_bikes <- agg_serv_lvl_less_5_bikes$serv_lvl
agg_serv_lvl_less_5_bikes <- NULL
agg$groupbyfactor <- as.factor(agg$groupbyfactor)
agg <- as.ffdf(agg[,c("groupbyfactor","serv_lvl","serv_lvl_less_5_bikes")])
wdcMerged$dup <- duplicated(wdcMerged$groupbyfactor)
wdcMerged <- subset(wdcMerged,dup==FALSE)
wdcMerged <- merge(wdcMerged, agg, by="groupbyfactor")
agg <- NULL
wdcMerged <- as.data.frame(wdcMerged)
station_serv_lvl_effects <- wdcMerged
wdcMerged <- wdcMerged_dem
wdcMerged$week_tw <- paste0(wdcMerged$week,"_",wdcMerged$tw)
wdcMerged$groupbyfactor <- paste0(wdcMerged$week,"_",wdcMerged$tw,"_",
wdcMerged$station_id_index)
wdcMerged <- wdcMerged[order(wdcMerged$groupbyfactor,wdcMerged$stocked_out,-wdcMerged$obs_weight),]
wdcMerged$index <- ave(wdcMerged$station_id_index, wdcMerged$groupbyfactor, FUN=function(x)c(1:length(x)))
wdcMerged <- subset(wdcMerged, index<=4)
points <- generate_integration_points()
covariates_st <- gen_covariates(wdcMerged,points)
#for each points, find out stations that are in locality and store them as a string
station_data <- unique(wdcMerged[,c("station_id","lat","lon","station_id_index")])
station_data <- station_data[order(station_data$station_id_index),]
points$local_stations <- rep(NA,nrow(points))
for(i in 1:nrow(points)) {
lat1 = points$lat[i]
lon1 = points$lon[i]
dis_v <- latlondistance(lat1,lon1,station_data$lat,station_data$lon)
order_dis_v <- order(dis_v)
points$local_stations[i] =paste(station_data$station_id_index[sort(order_dis_v[which(dis_v[order_dis_v[1:point_range]] <= max_walking_dis)])]
, collapse="_")
}
wdcMerged$tw_group <- paste0(wdcMerged$week,"_",wdcMerged$tw)
wdcMerged$tw_group_fac <- as.factor(wdcMerged$tw_group)
wdcMerged$out_dem_mean <- wdcMerged$out_dem_sum/wdcMerged$obs_weight
wdcMerged <- wdcMerged[order(wdcMerged$week_tw,wdcMerged$station_id_index),]
######################################################################
market_share = 0.05
tract_in <- tract
points <- subset(points, tract %in% tract_in)
for(tract_in in tract) {
wdcMerged_tract <- wdcMerged[which(wdcMerged$tract == tract_in),]
net_demand = max(as.numeric(by(wdcMerged_tract$out_dem_mean, wdcMerged_tract$tw_group_fac, FUN=sum)))
points$density[which(points$tract %in% tract_in)] = net_demand/market_share/length(which(points$tract %in% tract_in))
}
#density vec
#   density_vec <- c(0.5911005757,0.2457243808,0.3320165761,0.2328666740,0.2322817986,
#                   0.2908310530,0.1138739657,0.1445517742,0.5464842092,0.4279953770)
#   for(tract_in in tract) {
#     points$density[which(points$tract %in% tract_in)] = density_vec[tract_in]
#   }
unique(points[,c("tract","density")])
current_serv_lvl <- data.frame(station_id_index= station_serv_lvl_effects$station_id_index)
current_serv_lvl$tw_group <- paste0(station_serv_lvl_effects$week,"_",station_serv_lvl_effects$tw)
current_serv_lvl$serv_lvl <- station_serv_lvl_effects$serv_lvl_less_5_bikes
current_serv_lvl$stid_twg_fac <- as.factor(paste(current_serv_lvl$station_id_index, current_serv_lvl$tw_group))
current_serv_lvl$instr_serv_lvl <- current_serv_lvl$serv_lvl
current_serv_lvl <- current_serv_lvl[order(current_serv_lvl$tw_group,current_serv_lvl$station_id_index),]
#     stop("failing due to less than no_st observations in most of the tw_group,
#          i.e. some of the stations are always stocked in particular tw_group.")
sttw_no <- ave(wdcMerged$station_id_index, wdcMerged$tw_group,
FUN=function(x) length(unique(x)))
x0_start <<- NULL
prev_theta <<- NULL
if(!identical(unique(wdcMerged$tw_group),unique(current_serv_lvl$tw_group))) stop("error")
source("reg_results_GMM_discoef_2.86_2.R")
gc()
}
}
#constants file
rm(list=ls())
if(.Platform$OS.type=="windows"  & Sys.info()["user"]=="Ashish") {
csv_dir <- "C:\\Users\\Ashish\\Desktop\\Velib Data\\CSVData"
work_dir <- "C:/Users/Ashish/Dropbox/Ashish_Karan/Sustainable Transportation System/Data/Code/R/Model_v6"
dropbox_dir <- "C:/Users/Ashish/Dropbox/Ashish_Karan"
} else {
if(.Platform$OS.type=="windows" & Sys.info()["user"]=="A") {
#incidates my XPS DELL Machine
work_dir <- "C:/Users/A/Dropbox/Ashish_Karan/Sustainable Transportation System/Data/Code/R/Model_v6"
csv_dir <- "C:/Users/A/Dropbox/VelibData/CSVData"
dropbox_dir <- "C:/Users/A/Dropbox/Ashish_Karan"
}
else {
if((Sys.info()["user"])=="ashish") {
#incidates my linux machine
work_dir <- "/home/ashish/Dropbox/Ashish_Karan/Sustainable Transportation System/Data/Code/R/Model_v6"
csv_dir <- "/home/ashish/Dropbox/VelibData/CSVData"
dropbox_dir <- "/home/ashish/Dropbox/Ashish_Karan"
#options(fftempdir="/home/ashish/fftempdir")
}
if(.Platform$OS.type=="unix"  & (Sys.info()["user"])=="ashishkabra") {
#incidates my macbook
work_dir <- "/Users/ashishkabra/Dropbox/Ashish_Karan/Sustainable Transportation System/Data/Code/R/Model_v6"
csv_dir <- "/Users/ashishkabra/Dropbox/VelibData/CSVData"
dropbox_dir <- "/Users/ashishkabra/Dropbox/Ashish_Karan"
#options(fftempdir="/home/ashish/fftempdir")
}
if((Sys.info()["user"])=="ak") {
#incidates my linux machine
work_dir <- "/home/ak/Dropbox/Ashish_Karan/Sustainable Transportation System/Data/Code/R/Model_v6"
csv_dir <- "/home/ak/Desktop/Velib_Data/CSVData"
dropbox_dir <- "/home/ak/Dropbox/Ashish_Karan"
}
if((Sys.info()["user"])=="rstudio") {
csv_dir <- "/home/rstudio/workspace/CSVData"
work_dir <- "/home/rstudio/Data/Model_v6"
dropbox_dir <- "/home/ubuntu/Dropbox/Ashish_Karan"
}
}
}
setwd(work_dir)
st_id_file <- "Paris/st_id_data_01_07_13.txt"
max_walking_dis <- 0.6
library('nloptr')
library('ffbase')
library('biglm')
library('sfsmisc')
library("Rcpp")
library("RcppArmadillo")
library("ipoptr")
library("plm")
library("sandwich")
source("setup.R")
options(digits=10)
#for ffdf chunk size
options(ffbatchbytes=167772160)
require("colorspace")
#obj.size <- napply(names, function(x) round(object.size(x)/1024^2,2))
.ls.objects <- function (pos = 1, pattern, order.by,
decreasing=FALSE, head=FALSE, n=5) {
napply <- function(names, fn) sapply(names, function(x)
fn(get(x, pos = pos)))
names <- ls(pos = pos, pattern = pattern)
obj.class <- napply(names, function(x) as.character(class(x))[1])
obj.mode <- napply(names, mode)
obj.type <- ifelse(is.na(obj.class), obj.mode, obj.class)
#obj.size <- napply(names, object.size)
obj.size <- napply(names, function(x) round(object.size(x)/1024^2,2))
obj.dim <- t(napply(names, function(x)
as.numeric(dim(x))[1:2]))
vec <- is.na(obj.dim)[, 1] & (obj.type != "function")
obj.dim[vec, 1] <- napply(names, length)[vec]
out <- data.frame(obj.type, obj.size, obj.dim)
names(out) <- c("Type", "Size", "Rows", "Columns")
if (!missing(order.by))
out <- out[order(out[[order.by]], decreasing=decreasing), ]
if (head)
out <- head(out, n)
out
}
# shorthand
lsos <- function(..., n=10) {
.ls.objects(..., order.by="Size", decreasing=TRUE, head=TRUE, n=n)
}
#This file generates data for observations weights=1 and assumed values of deltas and
#then estimates them
source("data_estimation_2.6_weather_saved.R")
#source("data_estimation_2.6_weather_small_saved.R")
source("eval_func_2_cpp_MPEC.R")
source("temp_read_google_places_data.R")
points_save <- points
wdcMerged_store <- wdcMerged
user_serv_lvl_store <- user_serv_lvl
wdcMerged <- wdcMerged_store
user_serv_lvl <- user_serv_lvl_store
current_serv_lvl <- user_serv_lvl_store
points <- points_save
#merge points w google places data
#merge points with places data
points <- points[order(points$type, points$lat, points$lon),]
places_data <- read_googleplaces_data()
#places_cols_select <- c("lat","lon","cafe", "grocery_or_supermarket", "local_government_office")
places_cols_select <- c("lat","lon","places_count")
places_data <- places_data[,places_cols_select]
places_data <- places_data[order(places_data$lat, places_data$lon),]
if(!identical(round(points$lat[c(1:nrow(places_data))],4), round(places_data$lat,4))) stop("points lat dont match")
if(!identical(round(points$lon[c(1:nrow(places_data))],4), round(places_data$lon,4))) stop("points lon dont match")
places_data_temp <- places_data
places_data_temp$lat <- NULL
places_data_temp$lon <- NULL
places_colnames <- colnames(places_data_temp)
places_data_temp_full <- as.data.frame(matrix(0,nrow=nrow(points),ncol=ncol(places_data_temp)))
colnames(places_data_temp_full) <- places_colnames
places_data_temp_full[c(1:nrow(places_data_temp)),] <- places_data_temp
points <- cbind(points, places_data_temp_full)
#make the weights to 1
#put a value of delta
#compute lambda
colnames_theta1 <<- c("dis coef","rand coef","density ridership","density metro","density intercept",
"density metro evening", "density google places count",
"density bus")
density_ridership_col <<- 3
density_metro_col <<- 4
density_intercept_col <<- 5
density_metro_evening_col <<- 6
density_google_places_count <<- 7
density_bus_col <<- 8
# #keeping "6_0" "6_3" and "7_0" "7_3"
# time_windows <- c("6_0","6_5","7_0","7_5")
# tws <- c("0","5")
# #time_windows <- c("6_3")
# wdcMerged <- subset(wdcMerged, tw_group_fac %in% time_windows)
# wdcMerged <- droplevels(wdcMerged)
# levels(wdcMerged$tw_group_fac)
# user_serv_lvl <- subset(user_serv_lvl, tw %in% tws)
# user_serv_lvl <- droplevels(user_serv_lvl)
# unique(user_serv_lvl$tw)
#
# wdcMerged <- droplevels(wdcMerged)
# user_serv_lvl$st_tw_index <- as.numeric(user_serv_lvl$st_tw)
# wdcMerged$st_tw_index <- as.numeric(wdcMerged$st_tw)
rm(current_serv_lvl)
# #making 0 demand observations insignificant
# wdcMerged$obs_weight[which(wdcMerged$stocked_out==F & wdcMerged$out_dem_sum<=0.1)] <- 0.1
# wdcMerged$out_dem_sum <- wdcMerged$out_dem_sum/wdcMerged$obs_weight
# wdcMerged$obs_weight <- 1
#removing really low demand
wdcMerged$out_dem_sum[which(wdcMerged$out_dem_sum<=0.01 &
wdcMerged$stocked_out==FALSE)] <- 0.01
source("eval_func_2_cpp_MPEC.R")
length_stklist <- length(which(wdcMerged$stocked_out==F))
theta <- c(-4 , 1, 1, 1,1,1,1)
#choose starting values for deltain_stin
delta_all <- compute_delta_list_cntrt_map_new(c(theta[1],0,theta[-1]),wdcMerged, points)
deltain_stin <- delta_all[which(wdcMerged$stocked_out==F)]
params <- c(theta,deltain_stin)
lb = c(-20,rep(0.01,6),rep(-30, length_stklist))
ub = c(0,rep(1000000,6),rep(0, length_stklist))
constraint_lb <- c(rep(0, length_stklist), 100000)
constraint_ub <- c(rep(0, length_stklist), 100000)
eval_jac_g_structure_val <- eval_jac_g_structure(params, wdcMerged, points, length(theta))
